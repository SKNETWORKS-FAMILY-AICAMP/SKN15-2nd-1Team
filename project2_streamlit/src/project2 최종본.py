import streamlit as st
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.pyplot as plt
import joblib

# ì €ì¥ëœ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸°
model_lr = joblib.load("./model/model_lr.pkl")
model_lgb = joblib.load("./model/model_lgb.pkl")
model_cat = joblib.load("./model/model_cat.pkl")
num_features = joblib.load("./model/num_features.pkl")
feature_col = joblib.load("./model/feature_col.pkl")
scaler = joblib.load("./preprocessing/scaler.pkl")
encoder = joblib.load("./preprocessing/encoder.pkl")


# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ê³ ê° ì´íƒˆ ë¶„ì„", layout="wide")

# ì„¸ì…˜ ìƒíƒœë¡œ í˜ì´ì§€ ì´ë™ ê´€ë¦¬ í•¨ìˆ˜ ì •ì˜
def navigate(target):
    st.session_state.page = target

# ì´ˆê¸° ì„¸ì…˜ ìƒíƒœ ì„¤ì •
if 'page' not in st.session_state:
    st.session_state.page = "í™ˆ"

# ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
# í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
pages = ["í™ˆ", "ë°ì´í„° íƒìƒ‰ (EDA)", "ëª¨ë¸ë§", "ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜", "ì¸ì‚¬ì´íŠ¸ ìš”ì•½", "ì°¸ê³ ìë£Œ / íŒ€ ì†Œê°œ"]
icons = ["ğŸ ", "ğŸ“Š", "ğŸ§ ", "ğŸ”®", "ğŸ’¡", "ğŸ“š"]

# ì‚¬ì´ë“œë°” ì œëª©
st.sidebar.markdown("### ğŸŒ í˜ì´ì§€ ì´ë™")

# ë²„íŠ¼í˜• ë©”ë‰´
for i, p in enumerate(pages):
    if st.sidebar.button(f"{icons[i]} {p}"):
        st.session_state.page = p

# ê¸°ë³¸ê°’
if "page" not in st.session_state:
    st.session_state.page = "í™ˆ"

page = st.session_state.page

# ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (ìºì‹œ ì ìš©)
@st.cache_data
def load_data():
    return pd.read_csv("./data/cell2celltrain.csv")

df = load_data()

def preprocess_and_predict(df_raw):
    df = df_raw.copy()
    df = df[feature_col]
    df = df.dropna().reset_index(drop=True)

    # âœ… binary encoding
    binary_cols = [
        'Churn', 'ChildrenInHH', 'HandsetRefurbished', 'HandsetWebCapable', 'TruckOwner', 'RVOwner',
        'BuysViaMailOrder', 'RespondsToMailOffers', 'OptOutMailings', 'NonUSTravel',
        'OwnsComputer', 'HasCreditCard', 'NewCellphoneUser', 'NotNewCellphoneUser',
        'OwnsMotorcycle', 'MadeCallToRetentionTeam'
    ]
    for col in binary_cols:
        if col in df.columns:
            df[col] = df[col].map({'Yes': 1, 'No': 0})

    if 'Homeownership' in df.columns:
        df['Homeownership'] = df['Homeownership'].map({'Known': 1, 'Unknown': 0})

    # âœ… ë¼ë²¨ ì¸ì½”ë”©
    label_cols = ['ServiceArea', 'PrizmCode', 'Occupation']
    for col in label_cols:
        if col in df.columns:
            try:
                df[col] = encoder[col].transform(df[col].astype(str))
            except Exception as e:
                raise ValueError(f"âš  ë¼ë²¨ ì¸ì½”ë”© ì‹¤íŒ¨: '{col}' ì»¬ëŸ¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜\n{str(e)}")

    # âœ… ê¸°íƒ€ ì¸ì½”ë”© ë° ë³€í™˜
    if 'HandsetPrice' in df.columns:
        df['HandsetPrice'] = df['HandsetPrice'].replace('Unknown', 0).astype(float)

    if 'CreditRating' in df.columns:
        df['CreditRating'] = df['CreditRating'].astype(str).str.split('-').str[0].astype(int)

    if 'MaritalStatus' in df.columns:
        df['MaritalStatus'] = df.apply(
            lambda row: 'Yes' if row['MaritalStatus'] == 'Unknown' and row['AgeHH2'] != 0 else (
                -1 if row['MaritalStatus'] == 'Unknown' else row['MaritalStatus']
            ), axis=1
        )
        df['MaritalStatus'] = df['MaritalStatus'].map({'Yes': 1, 'No': 0, -1: -1})

    # âœ… ìŠ¤ì¼€ì¼ë§
    df_num = df[num_features]
    df_cat = df.drop(columns=num_features)

    df_scaled = pd.DataFrame(
        scaler.transform(df_num), columns=num_features, index=df.index
    )
    df_final = pd.concat([df_scaled, df_cat], axis=1)

    # âœ… ì˜ˆì¸¡
    proba_lgb = model_lgb.predict_proba(df_final)[:, 1]
    proba_cat = model_cat.predict_proba(df_final)[:, 1]
    proba_lr = model_lr.predict_proba(df_final)[:, 1]

    avg_proba = np.mean([proba_lgb, proba_cat, proba_lr], axis=0)
    pred = (avg_proba > 0.5).astype(int)

    df_result = df_raw.copy().dropna().reset_index(drop=True) 
    df_result["Churn_Probability (%)"] = np.round(avg_proba * 100, 2)
    df_result["Churn_Prediction"] = pred

    return df_result

# 1ï¸âƒ£ í™ˆ í˜ì´ì§€
if page == "í™ˆ":
    st.title("ğŸ“± í†µì‹ ì‚¬ ê³ ê° ì´íƒˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

    st.markdown("""
    ### ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”
    - **ëª©í‘œ:** ê³ ê° ì´íƒˆ ìœ ë¬´ ì˜ˆì¸¡ ë° ìš”ì¸ ë¶„ì„
    - **ë°ì´í„°ì…‹:** Cell2Cell í†µì‹ ì‚¬ì˜ ê³ ê° ì´íƒˆ ê´€ë ¨ ë°ì´í„°
    - **í™œìš©:** ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ìˆ˜ë¦½ ë° ê³ ê° ìœ ì§€ ì „ëµ ê°œë°œ
    """)

    st.markdown("---")
    st.subheader("ğŸ” í˜ì´ì§€ êµ¬ì„±")
    col1, col2 = st.columns(2)

    with col1:
        st.info("**1. ë°ì´í„° íƒìƒ‰ (EDA)**\n- ê³ ê° ë¶„í¬\n- ì´íƒˆ ì—¬ë¶€ë³„ íŠ¹ì„± ë¹„êµ\n- ìƒê´€ê´€ê³„ ë¶„ì„")
        st.button("ğŸ‘‰ EDA í˜ì´ì§€ë¡œ ì´ë™", on_click=navigate, args=("ë°ì´í„° íƒìƒ‰ (EDA)",))

        st.info("**2. ëª¨ë¸ë§**\n- ë¡œì§€ìŠ¤í‹± íšŒê·€, ëœë¤í¬ë ˆìŠ¤íŠ¸, XGBoost\n- ì„±ëŠ¥ í‰ê°€ ë° ROC Curve")
        st.button("ğŸ‘‰ ëª¨ë¸ë§ í˜ì´ì§€ë¡œ ì´ë™", on_click=navigate, args=("ëª¨ë¸ë§",))

        st.info("**3. ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜**\n- ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ì´íƒˆ ì˜ˆì¸¡\n- ì´íƒˆ í™•ë¥ ê³¼ ê°„ë‹¨í•œ í•´ì„ ì œê³µ")
        st.button("ğŸ‘‰ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ ì´ë™", on_click=navigate, args=("ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜",))

        st.info("**4. ì¸ì‚¬ì´íŠ¸ ìš”ì•½**\n- ì£¼ìš” ë³€ìˆ˜ ì •ë¦¬\n- ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ì œì•ˆ\n- ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ")
        st.button("ğŸ‘‰ ì¸ì‚¬ì´íŠ¸ ìš”ì•½ ì´ë™", on_click=navigate, args=("ì¸ì‚¬ì´íŠ¸ ìš”ì•½",))

        st.info("**5. ì°¸ê³ ìë£Œ / íŒ€ ì†Œê°œ**\n- ë°ì´í„° ì¶œì²˜\n- íŒ€ êµ¬ì„± ë° ê¹ƒí—ˆë¸Œ ë§í¬")
        st.button("ğŸ‘‰ ì°¸ê³ ìë£Œ / íŒ€ ì†Œê°œ ì´ë™", on_click=navigate, args=("ì°¸ê³ ìë£Œ / íŒ€ ì†Œê°œ",))

# 2ï¸âƒ£ ë°ì´í„° íƒìƒ‰ (EDA)
elif page == "ë°ì´í„° íƒìƒ‰ (EDA)":
    st.header("ğŸ“Š ë°ì´í„° íƒìƒ‰ (EDA)")
    st.subheader("âœ… ë°ì´í„° ìƒ˜í”Œ")
    st.dataframe(df.head())

    tab1, tab2, tab3 = st.tabs(["ğŸ“Š ê³ ê° ë¶„í¬", "ğŸ“‰ ì´íƒˆ íŠ¹ì„± ë¹„êµ", "ğŸ” ìƒê´€ê´€ê³„ ë¶„ì„"])

    with tab1:
        st.subheader("ê³ ê° ì´íƒˆ ì—¬ë¶€ ë¶„í¬ ê·¸ë˜í”„")
        churn_counts = df["Churn"].value_counts()
        st.bar_chart(churn_counts)
        fig1, ax1 = plt.subplots()
        st.subheader("ê³ ê° ì´íƒˆ ì—¬ë¶€ ë¶„í¬ ë¹„ìœ¨")
        ax1.pie(churn_counts, labels=churn_counts.index, autopct="%1.1f%%", startangle=90)
        ax1.axis("equal")
        st.pyplot(fig1)

    with tab2:
        st.subheader("ğŸ“Š íŠ¹ì„±ë³„ ì´íƒˆ ì—¬ë¶€ ë¶„í¬")

        target_cols = ['MonthsInService', 'CurrentEquipmentDays', 'TotalRecurringCharge', 'MonthlyMinutes']
        bins = 40

        for i, target_col in enumerate(target_cols):
            if target_col == 'MonthsInService':
                # âœ… ì„  ê·¸ë˜í”„: MonthsInServiceì— ëŒ€í•œ ì´íƒˆë¥  ë¶„í¬
                st.markdown("#### âœ… ì„œë¹„ìŠ¤ ê°œì›” ìˆ˜ì— ë”°ë¥¸ ì´íƒˆ ê³ ê° ë¶„í¬")

                # 1. ë¶„í¬ ê³„ì‚°
                count_df = df.groupby([target_col, 'Churn']).size().reset_index(name='Count')
                pivot_df = count_df.pivot(index=target_col, columns='Churn', values='Count').fillna(0)

                # 2. ì •ê·œí™”
                pivot_df['Yes_pct_norm'] = pivot_df['Yes'] / pivot_df['Yes'].sum()
                pivot_df['No_pct_norm'] = pivot_df['No'] / pivot_df['No'].sum()

                # 3. ì„  ê·¸ë˜í”„ ì‹œê°í™”
                fig1, ax1 = plt.subplots(figsize=(12, 6))
                ax1.plot(pivot_df.index, pivot_df['Yes_pct_norm'], label='Churn = Yes (Normalized)', linewidth=2)
                ax1.plot(pivot_df.index, pivot_df['No_pct_norm'], label='Churn = No (Normalized)', linewidth=2)
                ax1.set_title('ì„œë¹„ìŠ¤ ê°œì›” ìˆ˜ì— ë”°ë¥¸ ì´íƒˆ/ìœ ì§€ ê³ ê° ë¹„ìœ¨')
                ax1.set_xlabel('Months In Service')
                ax1.set_ylabel('Proportion (Normalized)')
                ax1.legend()
                ax1.grid(True)
                st.pyplot(fig1)

            else:
                # âœ… ë§‰ëŒ€ ê·¸ë˜í”„: ë‚˜ë¨¸ì§€ ë³€ìˆ˜
                st.markdown(f"#### âœ… {target_col}ì— ë”°ë¥¸ ì´íƒˆ ê³ ê° ìƒëŒ€ë„ìˆ˜")

                # êµ¬ê°„ ê²½ê³„ ë° ë¼ë²¨
                min_val = df[target_col].min()
                max_val = df[target_col].max()
                bin_edges = np.linspace(min_val, max_val, bins + 1)
                labels = [f"{int(bin_edges[i])}-{int(bin_edges[i+1])}" for i in range(len(bin_edges) - 1)]

                # êµ¬ê°„í™”
                df[f'{target_col}_bin'] = pd.cut(df[target_col], bins=bin_edges, labels=labels, include_lowest=True)

                # ìƒëŒ€ë„ìˆ˜ ê³„ì‚°
                rel_freq_df = pd.crosstab(
                    df[f'{target_col}_bin'], df["Churn"], normalize='columns'
                ).reset_index()

                # xì¶• ìœ„ì¹˜
                x = np.arange(len(rel_freq_df[f'{target_col}_bin']))
                yes_vals = rel_freq_df['Yes']
                no_vals = rel_freq_df['No']
                width = 0.4

                # ì‹œê°í™”
                fig, ax = plt.subplots(figsize=(14, 6))
                ax.bar(x - width / 2, yes_vals, width, label='Churn = Yes', alpha=0.8)
                ax.bar(x + width / 2, no_vals, width, label='Churn = No', alpha=0.8)
                ax.set_title(f"{target_col} êµ¬ê°„ë³„ ì´íƒˆ/ìœ ì§€ ê³ ê° ë¹„ìœ¨")
                ax.set_xlabel(target_col)
                ax.set_ylabel("Proportion")
                ax.set_xticks(x)
                ax.set_xticklabels(rel_freq_df[f'{target_col}_bin'], rotation=90, fontsize=8)
                ax.legend(title="Churn")
                ax.grid(axis='y', linestyle='--', alpha=0.6)
                plt.tight_layout()

                st.pyplot(fig)




    with tab3:
        numeric_df = df.select_dtypes(include=["int64", "float64"])
        corr = numeric_df.corr()
        fig4, ax4 = plt.subplots(figsize=(10, 8))
        sns.heatmap(corr, cmap="coolwarm", annot=False, ax=ax4)
        st.pyplot(fig4)

# 3ï¸âƒ£ ëª¨ë¸ë§ í˜ì´ì§€
elif page == "ëª¨ë¸ë§":
    st.header("ğŸ¤– ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½ (Soft Voting Classifier)")

    data = {
    "Models": ["XGBoost", "LGBM+CatBoost+Logistic"],
    "Train Accuracy": [0.8338, 0.7132],
    "Test Accuracy": [0.7162, 0.6388],
    "Train F1": [0.7564, 0.6020],
    "Test F1": [0.5595, 0.5029],
    "Train Recall": [0.7254, 0.7265],
    "Test Recall": [0.5644, 0.6386]
}

    # ì¸ë±ìŠ¤ë¥¼ ì œê±°í•œ DataFrame
    df1 = pd.DataFrame(data)

    # ì¸ë±ìŠ¤ë¥¼ ì œê±°í•˜ê³  í‘œ ì¶œë ¥
    st.subheader("ğŸ“‹ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    df1_reset = df1.reset_index(drop=True)
    st.table(df1_reset)

    st.subheader("ğŸ“Š ì‹œê°í™” ê²°ê³¼")

    col1, col2 = st.columns(2)

    with col1:
        st.image("./result_img/Confusion_Mateix.png", caption="Confusion Matrix - Soft Voting", use_container_width=True)

    with col2:
        st.image("./result_img/ROC.png", caption="ROC Curve - Soft Voting Classifier", use_container_width=True)



# 4ï¸âƒ£ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ í˜ì´ì§€
elif page == "ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜":
    st.header("ğŸ”® CSV ì—…ë¡œë“œ ê¸°ë°˜ ê³ ê° ì´íƒˆ ì˜ˆì¸¡")
    st.markdown("""
    ### ğŸ“ ì—…ë¡œë“œ ì•ˆë‚´
    - **í•„ìˆ˜ ì»¬ëŸ¼ ìˆ˜:** 57ê°œ ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    - **í•„ìˆ˜ ì»¬ëŸ¼:** ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ì»¬ëŸ¼ë“¤ê³¼ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤.
    - **ê²°ì¸¡ì¹˜:** `NaN` ë˜ëŠ” `Unknown` ë“±ì˜ ê²°ì¸¡ì¹˜ê°€ ìˆì„ ê²½ìš° í•´ë‹¹ í–‰ì€ ìë™ ì œê±°ë©ë‹ˆë‹¤.
    - **í˜•ì‹:** `csv` íŒŒì¼ í˜•ì‹ë§Œ ì§€ì›í•©ë‹ˆë‹¤. (ìµœëŒ€ 200MB)
    """)

    uploaded_file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])
    if uploaded_file:
        try:
            df_input = pd.read_csv(uploaded_file)
            result_df = preprocess_and_predict(df_input)

            st.success("âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
            st.dataframe(result_df.head())

            csv_result = result_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                data=csv_result,
                file_name="churn_prediction_result.csv",
                mime="text/csv"
            )
        except Exception as e:
            st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}")
    else:
        st.info("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì´íƒˆ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# 5ï¸âƒ£ ì¸ì‚¬ì´íŠ¸ ìš”ì•½ í˜ì´ì§€
elif page == "ì¸ì‚¬ì´íŠ¸ ìš”ì•½":
    st.header("ğŸ“˜ ì¸ì‚¬ì´íŠ¸ ìš”ì•½ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì œì•ˆ")
    st.markdown("""
    ### ğŸ“Œ ì£¼ìš” ì¸ì‚¬ì´íŠ¸
    - ì´íƒˆë¥ ì€ ê°€ì… í›„ ì•½ 2~12ê°œì›” ì‚¬ì´ê°€ ê°€ì¥ ë†’ìŒ
    - ê¸°ê¸° ì‚¬ìš© ì¼ìˆ˜(CurrentEquipmentDays) ê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ì´íƒˆë¥ ì´ ì¦ê°€
    - ë‚®ì€ ìš”ê¸ˆ ê³ ê°(RecurringCharge) ì´ ì´íƒˆ ë¹„ìœ¨ì´ ë†’ë‹¤.
    - ì‚¬ìš©ëŸ‰ì´ ì ì€ ê³ ê°(MonthlyMinutes) ì´ ì´íƒˆ ë¹„ìœ¨ì´ ë†’ìŒ.

    ### ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì œì•ˆ
    - ê°€ì… 6~12ê°œì›” ê³ ê°ì— ëŒ€í•œ ë¦¬í…ì…˜ í”„ë¡œê·¸ë¨ í•„ìˆ˜
    - ê¸°ê¸° êµì²´ ì‹œì  ë„ë‹¬ ê³ ê°ì—ê²Œ ìƒˆ ê¸°ê¸° ì—…ê·¸ë ˆì´ë“œ ì œì•ˆ
    - ìš”ê¸ˆì´ ë‚®ê³  ì‚¬ìš©ëŸ‰ì´ ì ì€ ê³ ê°ì„ ìœ„í•œ í”„ë¡œëª¨ì…˜ ê°•í™”
    - ê³ ê° ì‚¬ìš©ëŸ‰ ê¸‰ê° ê°ì§€ ì‹œ ìë™ ì•Œë¦¼ or í˜œíƒ ì œê³µ
    """)

# 6ï¸âƒ£ ì°¸ê³ ìë£Œ / íŒ€ ì†Œê°œ í˜ì´ì§€
elif page == "ì°¸ê³ ìë£Œ / íŒ€ ì†Œê°œ":
    st.header("ğŸ“š ì°¸ê³ ìë£Œ & íŒ€ ì†Œê°œ")
    st.markdown("""
    ### ğŸ”— ë°ì´í„° ì¶œì²˜
    - [Kaggle: Cell2Cell Dataset](https://www.kaggle.com/datasets)

    ### ğŸ‘¨â€ğŸ’» íŒ€ êµ¬ì„±
    - ê¸°í˜„íƒ (ë°ì´í„° ë¶„ì„(EDA))
    - ìµœì„œë¦°(ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€)    
    - ì´ì†Œì • (ì „ì²˜ë¦¬ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§)
    - ì„ê°€ì€ (ë°ì´í„° ë¶„ì„(EDA))
    - ê¹€ì£¼í˜• (Streamlit ì›¹ ì„œë¹„ìŠ¤ êµ¬í˜„)

    ### ğŸ“¬ GitHub
    - [í”„ë¡œì íŠ¸ ì €ì¥ì†Œ](https://github.com/SKNETWORKS-FAMILY-AICAMP/SKN15-2nd-1Team)
    """)
